# RetiCardNet â€” Retinal Cardiovascular Risk Prediction Network

A state-of-the-art multi-modal deep learning framework for predicting cardiovascular disease risk from retinal fundus images.

## ğŸ¯ Overview

RetiCardNet combines three powerful modalities to predict cardiovascular risk:
1. **Vision Transformer (ViT)** - Analyzes global retinal image features
2. **Graph Neural Network (GNN)** - Learns vessel topology and structure
3. **Clinical Features** - Integrates patient metadata (Age, BP, BMI)

The model uses a novel **Cross-Attention Fusion** mechanism to intelligently combine these modalities for superior prediction accuracy.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RetiCardNet                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Fundus Image â”‚  â”‚ Vessel Graph â”‚  â”‚   Clinical   â”‚     â”‚
â”‚  â”‚  (224Ã—224)   â”‚  â”‚  (500 nodes) â”‚  â”‚  (Age,BP,BMI)â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                 â”‚                  â”‚             â”‚
â”‚         â–¼                 â–¼                  â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚     ViT      â”‚  â”‚  GNN (GCN)   â”‚  â”‚     MLP      â”‚     â”‚
â”‚  â”‚  (vit_b_16)  â”‚  â”‚  3 Layers    â”‚  â”‚  3 Layers    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                 â”‚                  â”‚             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                   â–¼                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚         â”‚  Cross-Attention    â”‚                            â”‚
â”‚         â”‚  Fusion (4 heads)   â”‚                            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                   â–¼                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚         â”‚  Prediction Head    â”‚                            â”‚
â”‚         â”‚  (Low/Mod/High)     â”‚                            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Dataset

- **Source**: Kaggle Fundus Dataset (APTOS, DDR, IDRiD, EyePACs, Messidor)
- **Total Images**: 3,660 retinal fundus images
- **Classes**: 3 cardiovascular risk levels (Low, Moderate, High)
- **Split**: 70% train / 15% val / 15% test
- **Clinical Features**: Simulated Age, Systolic BP, BMI correlated with risk

## ğŸš€ Quick Start

### Installation

```bash
# Install dependencies
pip install torch torchvision torch_geometric
pip install opencv-python scikit-image scipy pandas numpy
pip install scikit-learn tqdm
```

### Data Preparation

```bash
# Generate clinical data and split dataset
python data_setup.py
```

This creates `clinical_data.csv` with:
- Image paths
- DR grades (0-4)
- CV risk labels (0-2)
- Simulated clinical features

### Training

```bash
# Train the model
python train.py --epochs 20 --batch_size 8 --lr 0.0001
```

**Arguments:**
- `--epochs`: Number of training epochs (default: 10)
- `--batch_size`: Batch size (default: 8)
- `--lr`: Learning rate (default: 1e-4)
- `--csv_file`: Path to clinical data CSV

### Evaluation

```bash
# Evaluate on test set
python evaluate.py --checkpoint best_reticardnet.pth
```

**Metrics Computed:**
- Accuracy
- F1-Score
- Precision & Recall
- ROC-AUC
- Confusion Matrix

## ğŸ“ Project Structure

```
e:\HD_Model\Antigravity\
â”œâ”€â”€ data_setup.py              # Dataset preparation
â”œâ”€â”€ dataset.py                 # PyTorch Dataset with graph extraction
â”œâ”€â”€ model_components.py        # ViT, GNN, MLP, Fusion modules
â”œâ”€â”€ reticardnet.py            # Main model architecture
â”œâ”€â”€ train.py                  # Training script
â”œâ”€â”€ evaluate.py               # Evaluation script
â”œâ”€â”€ verify_pipeline.py        # Pipeline verification
â”œâ”€â”€ clinical_data.csv         # Generated clinical data
â”œâ”€â”€ best_reticardnet.pth      # Best model checkpoint
â””â”€â”€ dataset/                  # Fundus images
    â””â”€â”€ split_dataset/
        â””â”€â”€ test/
            â”œâ”€â”€ 0/            # DR grade 0 (Low risk)
            â”œâ”€â”€ 1/            # DR grade 1 (Moderate risk)
            â”œâ”€â”€ 2/            # DR grade 2 (Moderate risk)
            â”œâ”€â”€ 3/            # DR grade 3 (High risk)
            â””â”€â”€ 4/            # DR grade 4 (High risk)
```

## ğŸ”¬ Technical Details

### Vessel Graph Construction

1. **Preprocessing**: CLAHE enhancement on green channel
2. **Segmentation**: Adaptive thresholding
3. **Skeletonization**: Morphological thinning
4. **Graph Building**: k-NN graph (k=5) using scipy's cKDTree
5. **Downsampling**: Max 500 nodes per graph for efficiency

### Multi-Modal Fusion

The Cross-Attention layer performs:
```python
# Stack modalities
features = [img_emb, graph_emb, clinical_emb]  # Each: (B, 128)
stacked = stack(features, dim=1)                # (B, 3, 128)

# Multi-head attention
attended = MultiHeadAttention(stacked)          # (B, 3, 128)

# Residual + Norm + Pool
output = mean(LayerNorm(stacked + attended))    # (B, 128)
```

### Training Configuration

| Parameter | Value |
|-----------|-------|
| Optimizer | AdamW |
| Learning Rate | 1e-4 |
| Weight Decay | 1e-4 |
| Scheduler | CosineAnnealingLR |
| Loss Function | CrossEntropyLoss |
| Batch Size | 8 |
| Epochs | 20 |

## ğŸ¯ Performance Target

- **Target Accuracy**: â‰¥90%
- **Current Status**: Training in progress
- **Expected**: High accuracy due to multi-modal fusion

## ğŸ”‘ Key Features

âœ… **Multi-Modal Learning**: Combines image, graph, and clinical data  
âœ… **Vessel Topology**: GNN captures vascular structure  
âœ… **Attention Fusion**: Dynamic modality weighting  
âœ… **Pretrained ViT**: Transfer learning from ImageNet  
âœ… **Clinical Integration**: Seamless fusion of numerical features  
âœ… **Automated Pipeline**: End-to-end from images to predictions  

## ğŸ“š Citation

If you use this code, please cite:

```bibtex
@software{reticardnet2025,
  title={RetiCardNet: Multi-Modal Deep Learning for Cardiovascular Risk Prediction},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/reticardnet}
}
```

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

## ğŸ“§ Contact

For questions or collaborations, please open an issue on GitHub.

---

**Note**: This model is for research purposes. Clinical deployment requires regulatory approval and extensive validation.
